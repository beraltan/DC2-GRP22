{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "\n",
    "\n",
    "# Convert to CSV\n",
    "\n",
    "\n",
    "def lsoa_to_borough_mapping():\n",
    "    \n",
    "    data = pd.read_csv('data/secondary_data/lsoa_data/lsoa_data_iadatasheet1.csv')\n",
    "    if 'Unnamed: 1' in data.columns:\n",
    "        # Create the 'borough' column by stripping the numeric suffix and any whitespace from the 'Unnamed: 1' column\n",
    "        data['borough'] = data['Unnamed: 1'].str.extract(r'(^[\\D\\s]+)').apply(lambda x: x.str.strip())\n",
    "        \n",
    "        # Get the position of the 'Unnamed: 1' column\n",
    "        idx = data.columns.get_loc('Unnamed: 1')\n",
    "        \n",
    "        # Rearrange columns to place 'borough' right after 'Unnamed: 1'\n",
    "        cols = list(data.columns)\n",
    "        # Move 'borough' to the right position\n",
    "        new_cols = cols[:idx+1] + ['Borough'] + cols[idx+1:-1]  # assuming 'borough' is the last in the list\n",
    "        data = data[new_cols]\n",
    "        \n",
    "        # Save the modified dataframe back to CSV or return it\n",
    "        data.to_csv(file_path, index=False)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    # Rename 'Unnamed: 1' column to 'LSOA code'\n",
    "    data.rename(columns={'Unnamed: 1': 'LSOA code'}, inplace=True)\n",
    "    data = data[['LSOA code', 'Borough']]\n",
    "    \n",
    "    data.to_csv('data/lookup_tables/lsoa2borough.csv', index=False)\n",
    "    # Display the first few rows of the data\n",
    "    print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.lsoa_to_borough_mapping()>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoa_to_borough_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    with open('directory_structure.txt', 'w') as f:\n",
    "        for root, dirs, files in os.walk(startpath):\n",
    "            level = root.replace(startpath, '').count(os.sep)\n",
    "            indent = ' ' * 4 * (level)\n",
    "            f.write('{}{}/\\n'.format(indent, os.path.basename(root)))\n",
    "            subindent = ' ' * 4 * (level + 1)\n",
    "            for file in files:\n",
    "                f.write('{}{}\\n'.format(subindent, file))\n",
    "\n",
    "# Replace 'your_path_to_primary_data' with the path to your 'primary_data' directory.\n",
    "list_files('/Users/banana/Documents/GitHub/DC2-GRP22/data/primary_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file: ../data/primary_data/concatenated_csvs/metropolitan-stop-and-search.csv with 517765 rows.\n",
      "Created file: ../data/primary_data/concatenated_csvs/city-of-london-street.csv with 25221 rows.\n",
      "Created file: ../data/primary_data/concatenated_csvs/btp-street.csv with 175708 rows.\n",
      "Created file: ../data/primary_data/concatenated_csvs/metropolitan-street.csv with 3240987 rows.\n",
      "Created file: ../data/primary_data/concatenated_csvs/city-of-london-stop-and-search.csv with 7310 rows.\n",
      "Created file: ../data/primary_data/concatenated_csvs/metropolitan-outcomes.csv with 2556761 rows.\n",
      "Created file: ../data/primary_data/concatenated_csvs/city-of-london-outcomes.csv with 17825 rows.\n",
      "Created file: ../data/primary_data/concatenated_csvs/btp-stop-and-search.csv with 38315 rows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def concatenate_csv_files(base_dir, file_patterns):\n",
    "    # Create a new directory for concatenated CSVs\n",
    "    concatenated_dir = os.path.join(base_dir, 'concatenated_csvs')\n",
    "    os.makedirs(concatenated_dir, exist_ok=True)\n",
    "    \n",
    "    # Dictionary to hold the dataframes for each pattern\n",
    "    dataframes_dict = {pattern: [] for pattern in file_patterns}\n",
    "    \n",
    "    # Walk through the directory structure\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            # Check if the file matches any of the patterns\n",
    "            for pattern in file_patterns:\n",
    "                if pattern in file:\n",
    "                    # Read the CSV file and append to the correct list\n",
    "                    df = pd.read_csv(os.path.join(root, file))\n",
    "                    dataframes_dict[pattern].append(df)\n",
    "                    break\n",
    "    \n",
    "    # Now concatenate the dataframes for each pattern and write to a CSV file\n",
    "    for pattern, dfs in dataframes_dict.items():\n",
    "        if dfs:  # Check if there are any dataframes to concatenate\n",
    "            concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "            output_file = os.path.join(concatenated_dir, f'{pattern}.csv')\n",
    "            concatenated_df.to_csv(output_file, index=False)\n",
    "            print(f'Created file: {output_file} with {len(concatenated_df)} rows.')\n",
    "\n",
    "# Base directory path\n",
    "base_dir = '../data/primary_data'\n",
    "\n",
    "# List of unique patterns to match files for concatenation\n",
    "file_patterns = [\n",
    "    'metropolitan-stop-and-search', 'city-of-london-street', 'btp-street', \n",
    "    'metropolitan-street', 'city-of-london-stop-and-search', 'metropolitan-outcomes', \n",
    "    'city-of-london-outcomes', 'btp-stop-and-search'\n",
    "]\n",
    "\n",
    "# Call the function with the base directory and the list of file patterns\n",
    "concatenate_csv_files(base_dir, file_patterns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/primary_data'\n",
    "concatenated_dir = os.path.join(base_dir, 'concatenated_csvs')\n",
    "os.makedirs(concatenated_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DC2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
